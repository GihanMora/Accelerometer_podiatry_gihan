# -*- coding: utf-8 -*-
"""CNN_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eyc--ceh4kX8_eYdBJ_o-yqFlAiwZrrf
"""



from __future__ import print_function

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import datetime
from os import listdir, makedirs
from os.path import join, isfile, exists
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
import shutil
from tqdm import tqdm
from time import time
import keras
from tensorflow.keras.models import Sequential, load_model
import tensorflow.keras

# training_dataset_path = 'E:/Data/Accelerometer_Dataset_Rashmika/OA_data/supervised_data/ActivGraph/balanced/numpy_window-3600-overlap-0_train/'

# TIME_PERIODS = 3600
# model_checkpoint_path = 'E:/Projects/Accelerometer_OA_gihan/CNN_ACCL_OA/Model_outputs/CNN_graph_reg/balanced_train_unbalanced_test/temp_model_out/'

def load_data_1(filenames):

    X_data = []
    Y_data = []
    ID_user = []
    counter = 0
    for filename in tqdm(filenames):
        npy = np.load(filename, allow_pickle=True)
        X_data.append(npy.item().get('segments'))
        Y_data.append(npy.item().get('activity_classes'))

        user_id = filename.split('/')[-1][:6]
        data_length = npy.item().get('activity_classes').shape[0]
        ID_user.extend([user_id for _ in range(data_length)])

        # counter += 1
        # if counter > 5:
        #     break

    X_data = np.concatenate(X_data, axis=0)
    Y_data = np.concatenate(Y_data, axis=0)
    # print('yydata', Y_data)
    # Data relabeling from index 0 (use only 3 classes)
    Y_data = np.where(Y_data == 1, 0, Y_data)
    Y_data = np.where(Y_data == 2, 1, Y_data)
    Y_data = np.where(Y_data == 3, 2, Y_data)
    Y_data = np.where(Y_data == 4, 2, Y_data)
    # print('yydata',Y_data)
    return X_data, Y_data, ID_user
def load_data(filenames):

    X_data = []
    Y_data = []
    ID_user = []
    timestamp = []
    counter = 0
    for filename in tqdm(filenames):
        print(filename)

        npy = np.load(filename, allow_pickle=True)
        X_data.append(npy.item().get('segments'))
        Y_data.append(npy.item().get('energy_e'))

        user_id = filename.split('/')[-1][:6]
        data_length = npy.item().get('energy_e').shape[0]
        s_time = filename.split('/')[-1].split('RAW_')[1].split('_to_')[0].split(' ')
        s_t, s_d = s_time[1].split('-'), s_time[0].split('-')
        dt = datetime.datetime(int(s_d[0]), int(s_d[1]), int(s_d[2]), int(s_t[0]), int(s_t[1]), int(s_t[2]))
        step = datetime.timedelta(seconds=60)

        for t in range(data_length):
            timestamp.append(dt.strftime('%Y-%m-%d %H:%M:%S'))
            dt += step
        # print(time_stamps)
        ID_user.extend([user_id for _ in range(data_length)])

        # counter += 1
        # if counter > 5:
        #     break



    X_data = np.concatenate(X_data, axis=0)
    Y_data = np.concatenate(Y_data, axis=0)

    return X_data, Y_data, ID_user, timestamp

print('hi')

input_shape = 18000
model_m =  load_model('E:\Projects\Accelerometer_podiatry_gihan\Analysis\models\\regress_window_6000_overlap_3000_model.h5')
model_m_1 =  load_model('E:\Projects\Accelerometer_podiatry_gihan\Analysis\models\\classif_window_6000_overlap_3000_model.h5')


participants = []
ids = [1,2,3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]
for i in ids:
    if(i<10):
        st = 'Participant_00'+str(i)
    else:
        st = 'Participant_0' + str(i)
    participants.append(st)
print(participants)
for p in participants:
    test_dataset_path = 'E:\Data\Accelerometer_Dataset_Rashmika\Podiatry Data\\numpy_arrays_test\\'+p+'/numpy_window-6000-overlap-0/'
    MODEL_FOLDER = 'E:\Data\Accelerometer_Dataset_Rashmika\Podiatry Data\Predictions\\'+p+'\\'

    if not exists(test_dataset_path):
        makedirs(test_dataset_path)
    if not exists(MODEL_FOLDER):
        makedirs(MODEL_FOLDER)

    test_data_files = [join(test_dataset_path, f) for f in listdir(test_dataset_path) if isfile(join(test_dataset_path, f))]
    print(test_data_files)
    test_X_data, test_Y_data, test_ID_user, timestamp = load_data(test_data_files)
    test_X_data = test_X_data.reshape(test_X_data.shape[0], input_shape).astype("float32")

    print('first',test_X_data.shape)
    # test_X_data = test_X_data.astype("float32")
    test_Y_data = test_Y_data.astype("float32")
    y_pred_test = model_m.predict(test_X_data)
    y_pred_test_1d_list = [list(i)[0] for i in list(y_pred_test)]
    print(timestamp)
    print(y_pred_test_1d_list)
    # print(len(timestamp),len(y_pred_test_1d_list))
    out_csv= pd.DataFrame()
    out_csv['Timestamp'] = timestamp
    out_csv['EE'] = y_pred_test_1d_list


    num_classes = 3
    test_X_data, test_Y_data, test_ID_user = load_data_1(test_data_files)
    test_X_data = test_X_data.reshape(test_X_data.shape[0], input_shape).astype("float32")
    test_Y_data = test_Y_data.astype("float32")
    test_Y_data = tensorflow.keras.utils.to_categorical(test_Y_data, num_classes)
    y_pred_test = model_m_1.predict(test_X_data)
    max_y_pred_test = np.argmax(y_pred_test, axis=1)
    y_pred_test_1d_list = [int(i)+1 for i in list(max_y_pred_test)]
    print(y_pred_test_1d_list)
    category_l = []
    for i in y_pred_test_1d_list:
        if(i==1):
            category_l.append('SB')
        if (i == 2):
            category_l.append('LPA')
        if (i == 3):
            category_l.append('MVPA')
    print(category_l)
    # print(len(category_l))
    out_csv['PA_intensitivity'] = y_pred_test_1d_list
    out_csv['PA_Category'] = category_l

    out_csv.to_csv(MODEL_FOLDER+'/predictions.csv')
